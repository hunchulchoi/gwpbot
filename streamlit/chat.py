from datetime import datetime
import streamlit as st
import streamlit.components.v1 as components

import uuid
import time
import logging
import re
import os
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # dotenvê°€ ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ë§Œ ì‚¬ìš© (Streamlit Cloud Secrets ì‚¬ìš©)
    pass

from llm import get_ai_message
from llm import LLMModel
from llm import EmbeddingModel
from llm import save_log_to_supabase
from llm import add_legal_references_to_answer
from logger_config import setup_logging

logger = logging.getLogger(__name__)


# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê¹… ì„¤ì •
setup_logging()

llm_model: LLMModel = LLMModel.GPT_5_NANO
embedding_model: EmbeddingModel = EmbeddingModel.OPENAI


# session_id ì´ˆê¸°í™”: ì¿ í‚¤ì—ì„œ device_idë¥¼ í™•ì¸í•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±
if 'session_id' not in st.session_state:
  # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì—ì„œ device_id í™•ì¸ (JavaScriptê°€ ì¿ í‚¤ì—ì„œ ì½ì–´ì„œ ì„¤ì •í•œ ê°’)
  device_id = st.query_params.get('device_id')
  
  if device_id:
    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì— device_idê°€ ìˆìœ¼ë©´ ì‚¬ìš© (ì¿ í‚¤ì—ì„œ ì½ì€ ê°’)
    session_id = device_id
    st.session_state.session_id = session_id
  else:
    # ì—†ìœ¼ë©´ ìƒˆ UUID ìƒì„±í•˜ê³  ì¿ í‚¤ì— ì €ì¥í•˜ë„ë¡ JavaScript ì‹¤í–‰
    new_uuid = str(uuid.uuid4())
    components.html(f"""
    <script>
      (function() {{
        // ì¿ í‚¤ì—ì„œ device_id ì½ê¸°
        function getCookie(name) {{
          const value = `; ${{document.cookie}}`;
          const parts = value.split(`; ${{name}}=`);
          if (parts.length === 2) return parts.pop().split(';').shift();
          return null;
        }}
        
        // ì¿ í‚¤ì— device_id ì„¤ì •í•˜ê¸°
        function setCookie(name, value, days = 365) {{
          const expires = new Date();
          expires.setTime(expires.getTime() + (days * 24 * 60 * 60 * 1000));
          // secure í”Œë˜ê·¸: HTTPS ì—°ê²°ì—ì„œë§Œ ì¿ í‚¤ ì „ì†¡
          // httpOnlyëŠ” JavaScriptì—ì„œ ì„¤ì • ë¶ˆê°€ (ì„œë²„ì—ì„œë§Œ ì„¤ì • ê°€ëŠ¥)
          const isSecure = window.location.protocol === 'https:';
          const secureFlag = isSecure ? ';secure' : '';
          document.cookie = `${{name}}=${{value}};expires=${{expires.toUTCString()}};path=/${{secureFlag}};SameSite=Lax`;
        }}
        
        let deviceId = getCookie('device_id');
        if (!deviceId) {{
          deviceId = '{new_uuid}';
          setCookie('device_id', deviceId, 365); // 1ë…„ê°„ ìœ ì§€
        }}
        
        // URLì— device_idë¥¼ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ì¶”ê°€
        const url = new URL(window.location);
        if (!url.searchParams.has('device_id')) {{
          url.searchParams.set('device_id', deviceId);
          window.history.replaceState({{}}, '', url);
          // í˜ì´ì§€ ë¦¬ë¡œë“œí•˜ì—¬ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ Streamlitì—ì„œ ì½ì„ ìˆ˜ ìˆê²Œ í•¨
          window.location.reload();
        }}
      }})();
    </script>
    """, height=0)
    # JavaScriptê°€ ë¦¬ë¡œë“œë¥¼ íŠ¸ë¦¬ê±°í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ ìƒˆ UUID ì‚¬ìš©
    session_id = new_uuid
    st.session_state.session_id = session_id
else:
  session_id = st.session_state.session_id

st.set_page_config(page_title="ë§ì¶¤í˜•ë³µì§€ ì±—ë´‡", page_icon=":robot_face:")

# ì¸ì¦ ìƒíƒœ í™•ì¸
if 'authenticated' not in st.session_state:
  st.session_state.authenticated = False
if 'failed_attempts' not in st.session_state:
  st.session_state.failed_attempts = 0
if 'blocked_until' not in st.session_state:
  st.session_state.blocked_until = None

# ë¹„ë°€ë²ˆí˜¸ í™•ì¸ (ì²˜ìŒ ì ‘ì† ì‹œ)
if not st.session_state.authenticated:
  current_time = time.time()
  
  # ì ‘ê·¼ ê¸ˆì§€ ì‹œê°„ í™•ì¸
  if st.session_state.blocked_until and current_time < st.session_state.blocked_until:
    remaining_time = int((st.session_state.blocked_until - current_time) / 60)  # ë¶„ ë‹¨ìœ„
    remaining_seconds = int((st.session_state.blocked_until - current_time) % 60)
    
    st.title("ğŸ” ì ‘ê·¼ ê¸ˆì§€")
    st.error(f"ë¹„ë°€ë²ˆí˜¸ë¥¼ ì—¬ëŸ¬ ë²ˆ í‹€ë ¤ì„œ ì ‘ê·¼ì´ ê¸ˆì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.warning(f"ì ‘ê·¼ ê°€ëŠ¥ ì‹œê°„ê¹Œì§€ {remaining_time}ë¶„ {remaining_seconds}ì´ˆ ë‚¨ì•˜ìŠµë‹ˆë‹¤.")
    st.stop()
  
  # ì ‘ê·¼ ê¸ˆì§€ ì‹œê°„ì´ ì§€ë‚¬ìœ¼ë©´ ì´ˆê¸°í™”
  if st.session_state.blocked_until and current_time >= st.session_state.blocked_until:
    st.session_state.blocked_until = None
    st.session_state.failed_attempts = 0
  
  st.title("ğŸ” ì ‘ê·¼ ê¶Œí•œ í™•ì¸")
  st.info("ì´ ì±—ë´‡ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
  
  if st.session_state.failed_attempts > 0:
    st.warning(f"ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ ì‹¤íŒ¨: {st.session_state.failed_attempts}íšŒ")
  
  # .envì—ì„œ ë¹„ë°€ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
  correct_password = os.getenv("CHATBOT_PASSWORD", "8022912")  # ê¸°ë³¸ê°’ì€ 8022912
  
  # st.formì„ ì‚¬ìš©í•˜ì—¬ ì—”í„° í‚¤ë¡œ ì œì¶œ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
  with st.form("password_form"):
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", max_chars=7, autocomplete="off")
    submitted = st.form_submit_button("í™•ì¸", use_container_width=True)
  
  # autofocusë¥¼ ìœ„í•œ JavaScript ì¶”ê°€
  components.html("""
    <script>
      (function() {
        // ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í•„ë“œì— autofocus
        const inputs = document.querySelectorAll('input[type="password"]');
        if (inputs.length > 0) {
          inputs[0].focus();
        }
        
        // ì—”í„° í‚¤ ì´ë²¤íŠ¸ ì²˜ë¦¬ (st.formì´ ì´ë¯¸ ì²˜ë¦¬í•˜ì§€ë§Œ ì¶”ê°€ ë³´ì¥)
        document.addEventListener('keydown', function(e) {
          if (e.key === 'Enter' && e.target.type === 'password') {
            // form submitì€ st.formì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬
          }
        });
      })();
    </script>
  """, height=0)
  
  if submitted:
    if password == correct_password:
      # ë¹„ë°€ë²ˆí˜¸ê°€ ë§ìœ¼ë©´ ì¸ì¦ ì„±ê³µ ë° ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™”
      st.session_state.authenticated = True
      st.session_state.failed_attempts = 0
      st.session_state.blocked_until = None
      st.rerun()
    else:
      # ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦¬ë©´ ì‹¤íŒ¨ íšŸìˆ˜ ì¦ê°€
      st.session_state.failed_attempts += 1
      
      # 3ë²ˆ ì´ìƒ í‹€ë¦¬ë©´ ì ‘ê·¼ ê¸ˆì§€
      if st.session_state.failed_attempts >= 3:
        # ì ‘ê·¼ ê¸ˆì§€ ì‹œê°„ ê³„ì‚°: 10ë¶„, 20ë¶„, 40ë¶„ (2ë°°ì”© ì¦ê°€)
        block_minutes = 10 * (2 ** (st.session_state.failed_attempts - 3))
        st.session_state.blocked_until = current_time + (block_minutes * 60)
        
        st.error(f"ë¹„ë°€ë²ˆí˜¸ë¥¼ {st.session_state.failed_attempts}íšŒ í‹€ë ¤ì„œ {block_minutes}ë¶„ê°„ ì ‘ê·¼ì´ ê¸ˆì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()
      else:
        st.error(f"ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ({st.session_state.failed_attempts}/3íšŒ ì‹¤íŒ¨)")
  
  st.stop()  # ì¸ì¦ ì „ì—ëŠ” ë‚˜ë¨¸ì§€ ì½”ë“œ ì‹¤í–‰ ì¤‘ë‹¨

st.title("ğŸ¤– ë§ì¶¤í˜•ë³µì§€ ì±—ë´‡")
st.caption(f"ë§ì¶¤í˜• ë³µì§€ ì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.:(powered by {llm_model.value})")

if 'messages' not in st.session_state:
  st.session_state.messages = []

for message in st.session_state.messages:
  with st.chat_message(message["role"]):
    st.write(message["content"])

if user_question := st.chat_input(placeholder="ë§ì¶¤í˜•ë³µì§€ ì œë„ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
  # ë‹µë³€ ìƒì„± ì‹œê°„ ì¸¡ì • ì‹œì‘
  start_time = time.time()
  
  with st.chat_message("user"):
    st.write(user_question)
    st.session_state.messages.append({"role": "user", "content": user_question})

  with st.chat_message("assistant"):
    stream_generator, metadata = get_ai_message(user_question, llm_model, embedding_model, session_id)
    
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
    answer_container = st.empty()
    full_answer = ""
    qa_message = None
    
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
    all_chunks = []
    for chunk in stream_generator:
      chunk_text = ""
      all_chunks.append(chunk)  # ëª¨ë“  chunk ì €ì¥ (ë©”íƒ€ë°ì´í„° í™•ì¸ìš©)
      
      # chunkì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
      if hasattr(chunk, 'content'):
        chunk_text = chunk.content if chunk.content else ""
      elif isinstance(chunk, str):
        chunk_text = chunk
      elif hasattr(chunk, 'text'):
        chunk_text = chunk.text if chunk.text else ""
      
      if chunk_text:
        full_answer += chunk_text
        # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ë‹µë³€ í‘œì‹œ (ì»¤ì„œ í¬í•¨)
        answer_container.markdown(full_answer + "â–Œ", unsafe_allow_html=True)
    
    # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… ë‹µë³€ í‘œì‹œ (ì»¤ì„œ ì œê±°)
    answer_container.markdown(full_answer, unsafe_allow_html=True)
    
    # í† í° ì •ë³´ ì¶”ì¶œ: ëª¨ë“  chunkì—ì„œ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” chunk ì°¾ê¸°
    tokens_info = {}
    qa_message = None
    
    # ì—­ìˆœìœ¼ë¡œ í™•ì¸í•˜ì—¬ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ë§ˆì§€ë§‰ chunk ì°¾ê¸°
    for chunk in reversed(all_chunks):
      if hasattr(chunk, 'response_metadata') or hasattr(chunk, 'usage_metadata'):
        qa_message = chunk
        break
    
    # ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” chunkê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ chunk ì‚¬ìš©
    if not qa_message and all_chunks:
      qa_message = all_chunks[-1]
    
    if qa_message:
      # OpenAI í˜•ì‹: response_metadata['token_usage']
      if hasattr(qa_message, 'response_metadata'):
        response_metadata = qa_message.response_metadata
        if 'token_usage' in response_metadata:
          token_usage = response_metadata['token_usage']
          tokens_info = {
            'prompt_tokens': token_usage.get('prompt_tokens', 0),
            'completion_tokens': token_usage.get('completion_tokens', 0),
            'total_tokens': token_usage.get('total_tokens', 0)
          }
          logger.info(f"ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ í† í° ì •ë³´ ì¶”ì¶œ ì„±ê³µ (OpenAI): {tokens_info}")
      
      # Google Gemini í˜•ì‹: usage_metadata
      if not tokens_info and hasattr(qa_message, 'usage_metadata'):
        usage_metadata = qa_message.usage_metadata
        tokens_info = {
          'prompt_tokens': getattr(usage_metadata, 'input_tokens', 0),
          'completion_tokens': getattr(usage_metadata, 'output_tokens', 0),
          'total_tokens': getattr(usage_metadata, 'total_tokens', 0)
        }
        logger.info(f"ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ í† í° ì •ë³´ ì¶”ì¶œ ì„±ê³µ (Gemini): {tokens_info}")
    
    # ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì–»ì§€ ëª»í•œ ê²½ìš°, ë³„ë„ë¡œ invoke() í˜¸ì¶œí•˜ì—¬ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
    if not tokens_info:
      try:
        logger.info("ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ í† í° ì •ë³´ë¥¼ ì–»ì§€ ëª»í•´ ë³„ë„ë¡œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹œë„")
        from llm import get_llm, get_rag_chain, get_dictionary_chain
        from langchain_core.runnables import RunnableLambda
        
        # ì²´ì¸ ì¬êµ¬ì„± (ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ìš©) - ì´ë¯¸ ì´ˆê¸°í™”ëœ ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©
        dictionary_chain = get_dictionary_chain()
        history_aware_rag_chain = get_rag_chain()
        question_formatter = RunnableLambda(lambda x: {"question": x})
        rag_chain = dictionary_chain | question_formatter | history_aware_rag_chain
        config = {"configurable": {"session_id": session_id}}
        
        # invoke()ë¡œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (ë‹µë³€ì€ ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬)
        # ì£¼ì˜: ì´ëŠ” LLMì„ í•œ ë²ˆ ë” í˜¸ì¶œí•˜ë¯€ë¡œ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        qa_message_for_metadata = rag_chain.invoke({"question": user_question}, config=config)
        
        # í† í° ì •ë³´ ì¶”ì¶œ
        if hasattr(qa_message_for_metadata, 'response_metadata'):
          response_metadata = qa_message_for_metadata.response_metadata
          if 'token_usage' in response_metadata:
            token_usage = response_metadata['token_usage']
            tokens_info = {
              'prompt_tokens': token_usage.get('prompt_tokens', 0),
              'completion_tokens': token_usage.get('completion_tokens', 0),
              'total_tokens': token_usage.get('total_tokens', 0)
            }
            logger.info(f"í† í° ì •ë³´ ìˆ˜ì§‘ ì„±ê³µ: {tokens_info}")
        
        if not tokens_info and hasattr(qa_message_for_metadata, 'usage_metadata'):
          usage_metadata = qa_message_for_metadata.usage_metadata
          tokens_info = {
            'prompt_tokens': getattr(usage_metadata, 'input_tokens', 0),
            'completion_tokens': getattr(usage_metadata, 'output_tokens', 0),
            'total_tokens': getattr(usage_metadata, 'total_tokens', 0)
          }
          logger.info(f"í† í° ì •ë³´ ìˆ˜ì§‘ ì„±ê³µ (Gemini): {tokens_info}")
      except Exception as e:
        logger.warning(f"ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (í† í° ì •ë³´ ì—†ì´ ë¡œê·¸ ì €ì¥)
    
    metadata["tokens"] = tokens_info
    metadata["full_answer"] = full_answer
    
    # ë‹µë³€ ìƒì„± ì‹œê°„ ê³„ì‚°
    end_time = time.time()
    latency = end_time - start_time
    
    # <br> íƒœê·¸ ì²˜ë¦¬: í…Œì´ë¸” ë‚´ì—ì„œëŠ” HTML <br>ë¡œ ìœ ì§€, í…Œì´ë¸” ì™¸ë¶€ì—ì„œëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜
    # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ì²˜ë¦¬
    def process_br_tags(text):
      # í…Œì´ë¸” íŒ¨í„´ ì°¾ê¸° (|ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ëë‚˜ëŠ” ì¤„)
      lines = text.split('\n')
      result_lines = []
      in_table = False
      
      for line in lines:
        stripped = line.strip()
        # í…Œì´ë¸” ì‹œì‘/ì¢…ë£Œ ê°ì§€
        if '|' in line and (stripped.startswith('|') or stripped.endswith('|')):
          in_table = True
          # í…Œì´ë¸” ë‚´ì—ì„œëŠ” <br>ì„ HTMLë¡œ ìœ ì§€ (unsafe_allow_htmlë¡œ ë Œë”ë§)
          # ì´ë¯¸ <br> íƒœê·¸ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
          line = re.sub(r'<br\s*/?>', '<br>', line, flags=re.IGNORECASE)
        elif in_table and stripped and '|' not in line:
          # í…Œì´ë¸” ì¢…ë£Œ (ë¹ˆ ì¤„ì´ ì•„ë‹ˆê³  |ê°€ ì—†ëŠ” ì¤„)
          in_table = False
        elif not in_table:
          # í…Œì´ë¸” ì™¸ë¶€ì—ì„œëŠ” <br>ì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜
          line = re.sub(r'<br\s*/?>', '\n', line, flags=re.IGNORECASE)
        
        result_lines.append(line)
      
      # í…Œì´ë¸” ë‚´ë¶€ì˜ ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜ (í…Œì´ë¸” ì…€ ë‚´ë¶€ ì¤„ë°”ê¿ˆ ì²˜ë¦¬)
      # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ë¶„ì„í•˜ì—¬ í…Œì´ë¸” ì…€ ë‚´ë¶€ì˜ ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜
      result_text = '\n'.join(result_lines)
      
      # í…Œì´ë¸” í–‰ íŒ¨í„´: |ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ëŠ” ì¤„
      table_row_pattern = re.compile(r'^(\s*\|[^|\n]*\|[^|\n]*\|\s*)$', re.MULTILINE)
      
      def replace_newlines_in_table_cells(match):
        row = match.group(1)
        # ì…€ êµ¬ë¶„ì | ì‚¬ì´ì˜ ë‚´ìš©ì—ì„œ ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜
        # ë‹¨, ì´ë¯¸ <br> íƒœê·¸ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
        cells = row.split('|')
        processed_cells = []
        for i, cell in enumerate(cells):
          if i == 0 or i == len(cells) - 1:
            # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ì€ ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ ê³µë°±ë§Œ ìˆìŒ
            processed_cells.append(cell)
          else:
            # ì…€ ë‚´ë¶€ì˜ ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜ (ë‹¨, ì´ë¯¸ <br>ì´ ìˆìœ¼ë©´ ìœ ì§€)
            if '\n' in cell and '<br' not in cell.lower():
              cell = cell.replace('\n', '<br>')
            processed_cells.append(cell)
        return '|'.join(processed_cells)
      
      # í…Œì´ë¸” í–‰ ë‚´ë¶€ì˜ ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜
      result_text = table_row_pattern.sub(replace_newlines_in_table_cells, result_text)
      
      return result_text
    
    # <br> íƒœê·¸ ì²˜ë¦¬
    processed_answer = process_br_tags(full_answer)
    full_answer = processed_answer
    
    # ì²˜ë¦¬ëœ ë‹µë³€ìœ¼ë¡œ ì—…ë°ì´íŠ¸
    answer_container.markdown(full_answer, unsafe_allow_html=True)
    
    # ë²•ë ¹ ì°¸ì¡° ì¶”ê°€ (ë‹µë³€ì— ë²•ë ¹ëª…ì´ë‚˜ ì¡°í•­ì´ ìˆëŠ” ê²½ìš°)
    full_answer_with_legal_refs = add_legal_references_to_answer(full_answer)
    
    # ë²•ë ¹ ì°¸ì¡°ê°€ ì¶”ê°€ëœ ê²½ìš° ë‹µë³€ ì—…ë°ì´íŠ¸
    if full_answer_with_legal_refs != full_answer:
      st.markdown("---")
      st.markdown("**ê´€ë ¨ ë²•ë ¹ ì¡°í•­ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.**")
      # ë²•ë ¹ ì°¸ì¡° ë¶€ë¶„ë§Œ í‘œì‹œ
      legal_refs_section = full_answer_with_legal_refs[len(full_answer):]
      st.markdown(legal_refs_section)
      full_answer = full_answer_with_legal_refs
    
    st.session_state.messages.append({"role": "assistant", "content": full_answer})

    st.caption(f"ë‹µë³€ ìƒì„± ì‹œê°„: {latency:.2f} ì´ˆ ({len(full_answer) / latency:.2f} ì/ì´ˆ) @{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # ë¡œê·¸ ì €ì¥ (ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„)
    try:
      save_log_to_supabase(
        session_id=session_id,
        question=user_question,
        answer=full_answer,
        model=llm_model,
        latency=latency,
        tokens=metadata.get("tokens", {}),
        source_documents=metadata.get("context", [])
      )
    except Exception as e:
      logger.error(f"ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")