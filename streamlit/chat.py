import streamlit as st


from llm import get_ai_message
from llm import LLMModel
from llm import EmbeddingModel

llm_model: LLMModel = LLMModel.GPT_5_MINI
embedding_model: EmbeddingModel = EmbeddingModel.QWEN3_8B

st.set_page_config(page_title="ë§ì¶¤í˜•ë³µì§€ ì±—ë´‡", page_icon=":robot_face:")

st.title("ğŸ¤– ë§ì¶¤í˜•ë³µì§€ ì±—ë´‡")
st.caption(f"ë§ì¶¤í˜• ë³µì§€ ì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.:({llm_model.value}, {embedding_model.value})")

if 'messages' not in st.session_state:
  st.session_state.messages = []

for message in st.session_state.messages:
  with st.chat_message(message["role"]):
    st.write(message["content"])

if user_question := st.chat_input(placeholder="ë§ì¶¤í˜•ë³µì§€ ì œë„ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
  with st.chat_message("user"):
    st.write(user_question)
    st.session_state.messages.append({"role": "user", "content": user_question})

  with st.spinner("ë‹µë³€ì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):
    answer = get_ai_message(user_question, llm_model, embedding_model)

    with st.chat_message("assistant"):  
      full_answer = st.write_stream(answer)  # ë§ˆì§€ë§‰ ì²­í¬ë§Œ ìŠ¤íŠ¸ë¦¬ë°

    st.session_state.messages.append({"role": "assistant", "content": full_answer})